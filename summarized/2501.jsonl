{"id": "2501.00070", "reasoning_step": "在深入阅读这篇论文时，我首先关注了其核心问题：大型语言模型（LLMs）是否能够通过上下文学习（In-Context Learning, ICL）重新组织其预训练语义表示，以适应上下文指定的新语义。这一问题非常有趣，因为它涉及到模型的灵活性和适应性，而不仅仅是预训练数据的静态反映。论文通过一个创新的'图追踪'任务来探索这一问题，使用预定义的图结构（如网格、环形等）并将节点映射到常见概念（如苹果、鸟等），以观察模型是否能根据上下文中的随机游走轨迹重新组织表示。我注意到，论文在实验设计上非常细致，采用了多种图结构和不同模型进行验证，同时通过主成分分析（PCA）和Dirichlet能量等量化方法来分析表示的重组过程。然而，我也对实验结果的解释提出了一些疑问：尽管PCA可视化显示了表示的重组，但这种低维投影是否真正反映了模型内部的高维表示变化？此外，论文提出的能量最小化假设虽然理论上优雅，但是否完全解释了上下文学习中的突现行为仍需更多证据支持。另一个值得思考的点是，当上下文指定的语义与预训练语义冲突时，模型的表现如何受到影响？论文的结果表明上下文结构在更高主成分中出现，但未能主导预训练结构，这可能暗示模型对预训练语义的依赖性较强，限制了其完全适应新语义的能力。总体而言，这篇论文提供了一个新颖的视角来研究ICL，但其结论的普适性和机制解释仍需进一步验证和扩展。", "problem_background": "大型语言模型（LLMs）在预训练数据中组织概念表示的方式通常反映数据的语义结构，但当模型在开放环境中遇到与预训练语义不同的新语义时，是否能根据上下文重新组织表示仍是一个未解之谜。本文旨在探索这一问题：通过上下文学习（In-Context Learning, ICL），模型是否能将预训练语义调整为上下文指定的新语义？关键问题在于验证模型的表示灵活性，以及这种重组是否随着上下文规模的增加而突现（emergent）。", "slug": "in-context-learning-representations", "one_sentence_summary": "本文通过上下文图追踪任务揭示了大型语言模型能随上下文规模增加而突现地重组概念表示以适应新语义，并提出能量最小化假设解释这一过程。", "preference": "unknown", "updated": "2025-05-05", "top_p": 0.8, "method": "本文提出了一种名为'上下文图追踪'（In-Context Graph Tracing）的任务，用于研究模型表示的重组。具体方法如下：\n* **任务设计**：定义一个预设图结构（如方形网格、环形、六边形网格），图的节点映射到预训练中常见的概念（如苹果、鸟等），通过随机游走生成序列作为上下文输入模型，要求模型预测下一个有效节点。\n* **表示分析**：使用主成分分析（PCA）可视化模型中间层中每个概念的平均表示（mean token representations），观察表示是否随上下文规模增加而重组为图结构。\n* **量化方法**：引入Dirichlet能量作为度量，计算表示与图结构的对齐程度，能量越低表示模型表示越接近图的连接性；同时测量任务准确率（rule-following accuracy），以评估模型是否正确遵循图结构。\n* **理论假设**：提出能量最小化假设，认为模型通过隐式优化过程调整表示，以最小化Dirichlet能量，类似于图的谱嵌入（spectral embedding）。", "created": "2025-05-02", "authors": ["Core Francisco Park", "Andrew Lee", "Ekdeep Singh Lubana", "Yongyi Yang", "Maya Okawa", "Kento Nishi", "Martin Wattenberg", "Hidenori Tanaka"], "score": 0.8418473360497701, "experiment": "实验主要基于Llama-3.1-8B模型，并扩展到其他模型（如Llama3.2-1B、Gemma-2-2B等）进行验证，数据集为合成数据，通过随机游走生成图结构上的序列。实验设置包括三种图结构（方形网格、环形、六边形网格），并测试了不同上下文长度对表示重组和任务准确率的影响。结果表明：\n* **表示重组**：随着上下文示例数量增加，模型表示通过PCA可视化显示出与图结构一致的重组，例如在网格任务中表示形成网格状，在环形任务中形成环状。\n* **能量与准确率**：Dirichlet能量随上下文长度增加而下降，且在能量达到最小值后任务准确率迅速提升，表明表示重组先于任务表现改进。\n* **语义冲突**：当使用具有预训练语义相关性的概念（如星期几）时，上下文指定的图结构在更高主成分中出现，但无法主导预训练语义结构，显示出模型对预训练语义的依赖。\n* **评估合理性与局限**：实验设计较为全面，涵盖多种图结构和模型，但PCA作为低维可视化工具可能存在误导性，尽管通过Dirichlet能量和因果干预实验提供了补充证据；此外，能量最小化假设虽有理论支持，但未能完全解释突现行为的机制。总体而言，方法改进显著，但结果解释需谨慎，尤其是在语义冲突场景下的表现未达预期。", "institution": ["Harvard University", "NTT Research Inc.", "University of Michigan, Ann Arbor"], "source_file": "2501.00070.json", "keywords": ["Large Language Model", "In-Context Learning", "Representation Learning", "Emergent Abilities", "Long Context"], "temperature": 0.1, "model": "grok-3", "further_thoughts": "这篇论文的研究为理解上下文学习中的表示重组提供了一个新颖视角，但也引发了一些值得深入探讨的问题。首先，能量最小化假设虽然优雅，但是否适用于更复杂的自然语言任务仍需验证，例如在多模态或跨领域任务中，模型是否仍能通过类似机制重组表示？其次，论文中提到的语义冲突结果表明预训练语义对模型的影响根深蒂固，这与近期关于模型对齐（Alignment）和微调（Fine-tuning）的研究相呼应——是否可以通过特定的上下文设计或指令调整（Instruction Tuning）进一步削弱预训练语义的 dominance，从而提升模型对新语义的适应性？此外，论文与神经科学中关于人类大脑如何形成结构化表示的研究（如Garvert et al., 2017）建立了联系，这提示我们可以在人工智能与认知科学之间建立更深的桥梁，例如探索LLMs是否能在上下文学习中形成类似人类大脑中的'世界模型'（World Model），这对构建通用智能系统具有重要意义。最后，考虑到上下文规模的扩展可能解锁新能力，未来研究可以探索上下文长度与计算资源之间的权衡，以及如何设计更高效的上下文学习策略来提升模型性能。", "lang": "zh", "categories": ["cs.CL", "cs.AI", "cs.LG"], "summary_time": "2025-05-07T00:41:46.084431+00:00", "abstract": "Recent work has demonstrated that semantics specified by pretraining data influence how representations of different concepts are organized in a large language model (LLM). However, given the open-ended nature of LLMs, e.g., their ability to in-context learn, we can ask whether models alter these pretraining semantics to adopt alternative, context-specified ones. Specifically, if we provide in-context exemplars wherein a concept plays a different role than what the pretraining data suggests, do models reorganize their representations in accordance with these novel semantics? To answer this question, we take inspiration from the theory of conceptual role semantics and define a toy \"graph tracing\" task wherein the nodes of the graph are referenced via concepts seen during training (e.g., apple, bird, etc.) and the connectivity of the graph is defined via some predefined structure (e.g., a square grid). Given exemplars that indicate traces of random walks on the graph, we analyze intermediate representations of the model and find that as the amount of context is scaled, there is a sudden re-organization from pretrained semantic representations to in-context representations aligned with the graph structure. Further, we find that when reference concepts have correlations in their semantics (e.g., Monday, Tuesday, etc.), the context-specified graph structure is still present in the representations, but is unable to dominate the pretrained structure. To explain these results, we analogize our task to energy minimization for a predefined graph topology, providing evidence towards an implicit optimization process to infer context-specified semantics. Overall, our findings indicate scaling context-size can flexibly re-organize model representations, possibly unlocking novel capabilities.", "title": "ICLR: In-Context Learning of Representations"}
{"id": "2501.06143", "reasoning_step": "Upon deep diving into the paper, several critical points emerge that shape my understanding and critique. The study explores the performance of GPT-4o, a multimodal AI model, on physics concept inventories across multiple languages and subjects, using images to simulate real student experiences. This approach is novel but introduces complexities in data handling and interpretation due to the probabilistic nature of LLMs and manual data preparation. The significant variation in performance across languages raises concerns about training data bias and equity in educational applications. The consistent underperformance on tasks requiring visual interpretation suggests a fundamental limitation in current multimodal AI capabilities, which is critical for physics education where diagrams are integral. Additionally, the comparison with student performance, while insightful, lacks depth in analyzing whether AI errors mirror student misconceptions or stem from different causes. This prompts further thought on whether AI can truly replicate human-like conceptual understanding or if it merely excels at pattern recognition in certain domains. The language-switching behavior observed also hints at internal model biases that need further exploration. These insights guide my structured summary and critique, focusing on methodological rigor, result interpretation, and implications for educational technology.", "problem_background": "The rapid integration of Large Language Models (LLMs) like GPT-4o into education, particularly in physics, has opened new avenues for teaching and learning but also poses risks of over-reliance and inequity due to varying performance across languages and modalities. This study addresses the underexplored area of multimodal AI performance on physics concept inventories, focusing on multilingual contexts and visual interpretation challenges, aiming to assess how well such systems can handle diverse educational tasks compared to undergraduate students and identify limitations that could impact their responsible use in physics education.", "slug": "multilingual-multimodal-ai-physics-inventories", "one_sentence_summary": "This exploratory study evaluates GPT-4o's multilingual and multimodal performance on physics concept inventories, revealing strong results in English and text-based tasks but significant weaknesses in visual interpretation and non-Western languages, highlighting implications for equitable AI integration in education.", "preference": "unknown", "updated": "2025-05-13", "top_p": 0.8, "method": "The study evaluates GPT-4o’s performance by presenting physics concept inventories as images (screenshots) to mimic real student test materials, including diagrams and text in multiple languages, sourced from PhysPort. The methodology involves: (1) preparing 3,662 image files of inventory items covering various physics subjects; (2) submitting each image to GPT-4o via Microsoft Azure AI Services three times to account for probabilistic outputs, using structured JSON prompts in English to extract problem descriptions, reasoning, and answers; (3) analyzing performance across subject categories, languages, and image dependency (text-only, unneeded images, required images); and (4) comparing AI scores to published undergraduate post-instruction scores. The core idea is to test multimodal capabilities in a realistic educational setting, focusing on conceptual understanding rather than numerical computation.", "created": "2025-05-12", "authors": ["Gerd Kortemeyer", "Marina Babayeva", "Giulia Polverini", "Ralf Widenhorn", "Bor Gregorcic"], "score": 0.927752283195213, "experiment": "The experiments utilized a comprehensive dataset of 54 physics concept inventories from PhysPort, spanning subjects like mechanics, electromagnetism, and quantum physics, in 35 languages, resulting in 14,022 solutions for 4,674 items. The setup aimed to assess performance across diverse contexts, comparing English and non-English versions, and evaluating image dependency. Results showed an average performance of 71.1% in English, with significant variation across subjects (e.g., 85.2% in Thermodynamics, 35.0% in Laboratory Skills) and languages (e.g., 74% in Portuguese for FCI, 20% in Punjabi). GPT-4o outperformed average undergraduate post-instruction scores in most categories (68.9% of cases) except Laboratory Skills. However, it struggled with required-image items (49% accuracy vs. 81% for text-only), indicating a clear limitation in visual interpretation. The experimental design is comprehensive in scope but limited by manual data preparation, only three iterations per item, and potential translation quality issues, which may skew results. The performance disparity across languages suggests training data bias, and the setup does not fully explore reasoning quality, only final answers.", "institution": ["ETH Zurich", "Michigan State University", "Charles University", "Uppsala University", "Portland State University"], "source_file": "2501.06143.json", "keywords": ["Large Language Model", "Multimodality", "Multimodal Systems", "Reasoning", "Human-AI Interaction", "AI Ethics"], "temperature": 0.1, "model": "grok-3", "further_thoughts": "The findings of this paper raise deeper questions about the role of AI in education beyond mere performance metrics. The significant language disparity suggests a potential reinforcement of global educational inequities, as students in non-Western language contexts may not benefit equally from AI tools. This connects to broader discussions in AI ethics about bias in training data, as seen in works like those by Nicholas and Bhatia (2023), and calls for targeted efforts in diversifying datasets or developing language-specific models. Additionally, the struggle with visual interpretation aligns with ongoing challenges in computer vision and multimodal AI, suggesting a need for hybrid approaches that integrate specialized vision models with LLMs for subjects like physics where diagrams are crucial. This could tie into research on vision-language models like CLIP, exploring if such integrations improve performance on required-image tasks. Finally, the paper's observation that AI errors do not mirror student misconceptions opens a research avenue into whether AI can be trained to simulate student-like reasoning errors for pedagogical purposes, enhancing its utility as a teaching tool. These considerations underscore the necessity of a critical, equity-focused approach to AI deployment in education.", "lang": "en", "categories": ["physics.ed-ph", "cs.AI"], "summary_time": "2025-05-16T03:10:47.251011+00:00", "abstract": "We investigate the multilingual and multimodal performance of a large language model-based artificial intelligence (AI) system, GPT-4o, using a diverse set of physics concept inventories spanning multiple languages and subject categories. The inventories, sourced from the PhysPort website, cover classical physics topics such as mechanics, electromagnetism, optics, and thermodynamics, as well as relativity, quantum mechanics, astronomy, mathematics, and laboratory skills. Unlike previous text-only studies, we uploaded the inventories as images to reflect what a student would see on paper, thereby assessing the system's multimodal functionality. Our results indicate variation in performance across subjects, with laboratory skills standing out as the weakest. We also observe differences across languages, with English and European languages showing the strongest performance. Notably, the relative difficulty of an inventory item is largely independent of the language of the survey. When comparing AI results to existing literature on student performance, we find that the AI system outperforms average post-instruction undergraduate students in all subject categories except laboratory skills. Furthermore, the AI performs worse on items requiring visual interpretation of images than on those that are purely text-based. While our exploratory findings show GPT-4o's potential usefulness in physics education, they highlight the critical need for instructors to foster students' ability to critically evaluate AI outputs, adapt curricula thoughtfully in response to AI advancements, and address equity concerns associated with AI integration.", "title": "Multilingual Performance of a Multimodal Artificial Intelligence System on Multisubject Physics Concept Inventories"}
{"id": "2501.12352", "reasoning_step": "在深入阅读和分析这篇论文时，我首先关注了其核心思想，即通过测试时回归（test-time regression）框架统一理解和设计序列模型。这一框架基于关联回忆（associative recall）的概念，将记忆和检索过程形式化为回归问题。我注意到作者试图将多种序列模型（如线性注意力、状态空间模型、softmax注意力等）纳入这一框架，并通过回归问题的不同设计选择（如权重、回归函数类别和优化算法）推导出这些模型。这种统一视角非常有吸引力，因为它试图揭示不同架构背后的共性原理，而不仅仅是经验性的改进。\n\n然而，我对论文的实验部分持保留态度。实验主要集中在合成数据上的在线回归任务和多查询关联回忆（MQAR）任务，虽然这些实验展示了测试时回归层在单次前向传递中执行回归的能力，但缺乏在真实世界数据集（如语言建模或图像处理任务）上的广泛验证。这让我质疑框架的实际应用价值和泛化能力。此外，作者提出的softmax注意力高阶泛化（p=1的局部线性回归）虽然理论上有趣，但计算复杂度高，论文中也未提供有效的硬件优化方案，这可能限制其实用性。\n\n另一个值得思考的点是线性注意力为何表现不佳。作者指出这是因为它忽略了键向量之间的协方差，这种解释在数学上是合理的，但在实际训练中是否是主要瓶颈仍需更多证据支持。我还注意到，论文中提到的短卷积（short convolution）在构建键值对中的重要性，这与最近一些关于循环模型的研究相呼应，可能是一个值得进一步探索的方向。\n\n总的来说，这篇论文在理论上提供了有趣的视角，试图弥合序列建模与经典回归方法之间的差距，但其实际贡献和可操作性仍需通过更广泛的实验验证。我在总结时会平衡其创新性和局限性，确保对作者的努力给予公正评价，同时指出改进方向。", "problem_background": "序列模型是现代深度学习的核心，广泛应用于自然语言处理、计算机视觉和时间序列分析等领域。然而，近年来快速发展的各种序列架构（如Transformer、线性注意力、状态空间模型等）看似无关，缺乏统一的理论框架来理解其设计选择和性能差异。本文从关联回忆（associative recall）的经验重要性出发，提出一个统一的测试时回归（test-time regression）框架，旨在解决如何系统设计具有关联回忆能力的神经网络层这一关键问题，并试图揭示为何某些序列模型表现优于其他模型的潜在原理。", "slug": "test-time-regression-sequence-models", "one_sentence_summary": "本文提出一个基于测试时回归的统一框架，通过将关联回忆形式化为回归问题，推导出多种序列模型（如线性注意力、状态空间模型、softmax注意力），并通过合成实验验证其回归能力，同时提出高阶注意力泛化。", "preference": "unknown", "updated": "2025-05-05", "top_p": 0.8, "method": "本文提出了一种基于测试时回归的统一框架，用于设计具有关联回忆能力的序列模型，其核心思想和主要步骤如下：\n- **核心思想**：将关联回忆形式化为一个两步过程——记忆（memorization）和检索（retrieval），其中记忆过程被建模为一个加权回归问题。通过在每次前向传递中对输入token执行回归，生成一个依赖于输入的回归器，实现测试时回归。\n- **主要步骤**：\n  1. **记忆作为回归**：给定键值对（key-value pairs），通过解决加权回归问题（公式8）来构建一个关联记忆系统，回归器的目标是近似映射键到值，权重控制每个关联的重要性。\n  2. **检索作为函数应用**：将回归器应用于查询（query）向量，输出检索到的值（公式9）。\n  3. **设计选择**：通过三个设计选择推导出不同的序列层：(1) 回归权重（控制关联重要性），(2) 回归函数类别（如线性、非线性、局部多项式等），(3) 测试时优化算法（如解析解、梯度下降等）。\n- **具体推导**：作者通过上述框架推导了多种现有序列层，例如线性注意力被视为次优的线性最小二乘回归，忽略了键之间的协方差；状态空间模型和门控线性注意力对应于加权线性回归；快速权重层和在线学习层是流式最小二乘回归的一阶方法；softmax注意力则是局部常数非参数回归的一个特例。", "created": "2025-05-02", "authors": ["Ke Alexander Wang", "Jiaxin Shi", "Emily B. Fox"], "score": 0.7171244676801152, "experiment": "本文的实验设计主要围绕两个任务，验证测试时回归层在单次前向传递中执行回归的能力：\n- **在线回归任务**：使用合成的非平稳自回归过程生成键向量（维度64，序列长度256），值向量为归一化的下一时间步键向量，模拟下一token预测任务。实验比较了线性注意力、递归最小二乘（RLS）、softmax注意力及其高阶泛化（p=1局部线性回归）的单步预测误差。结果显示，线性注意力表现最差，因其忽略键协方差；非参数回归器（如softmax注意力）能适应数据变化，高阶泛化进一步提升了适应性。然而，实验仅限于合成数据，未涉及真实数据集，限制了结果的泛化性。\n- **多查询关联回忆（MQAR）任务**：测试模型在给定上下文序列后回忆特定线索-响应对的能力。实验使用单一测试时回归层和短卷积构建键值对，比较线性注意力和RLS的表现。结果表明，当模型容量足够时（如嵌入维度等于线索对数量），线性注意力能完美解决任务；RLS通过考虑键协方差在容量受限时表现更好。实验设计合理，验证了短卷积在构建键值对中的重要性，但仍局限于合成任务，缺乏真实语言建模场景的验证。\n- **总体评价**：实验设置较为简单，未能全面评估框架在复杂任务上的效果，改进幅度和实际应用价值尚待进一步验证。", "institution": ["Stanford University"], "source_file": "2501.12352.json", "keywords": ["Test Time", "Regression", "Associative Recall", "Sequence Modeling", "Attention Mechanisms", "Optimization Algorithms"], "temperature": 0.1, "model": "grok-3", "further_thoughts": "本文提出的测试时回归框架为序列建模提供了一个新颖的理论视角，特别是在关联回忆与回归之间的对应关系上，这可能启发我们重新审视大型语言模型（LLM）的上下文学习能力。例如，是否可以通过设计更复杂的回归函数类别或优化算法，进一步提升模型在长上下文任务中的表现？此外，短卷积在构建键值对中的重要性与最近一些关于循环模型（如RWKV、Mamba）的研究相呼应，是否可以将这一思想扩展到多模态数据处理中，通过短时窗口内的跨模态信息融合提升模型性能？\n\n另一方面，我认为本文的一个潜在局限是其对计算效率的关注不足，尤其是在高阶注意力泛化中，计算复杂性可能成为实际应用的瓶颈。这让我联想到FlashAttention等硬件优化技术，或许可以通过类似方法优化测试时回归层的计算。未来研究还可以探索如何将这一框架与联邦学习或在线学习结合，在动态环境中实现模型的实时适应和更新，从而进一步贴近Kohonen所描述的‘高级认知过程’的复杂性。", "lang": "zh", "categories": ["cs.LG", "cs.AI", "cs.NE", "stat.ML"], "summary_time": "2025-05-06T16:16:16.430014+00:00", "abstract": "Sequence models lie at the heart of modern deep learning. However, rapid advancements have produced a diversity of seemingly unrelated architectures, such as Transformers and recurrent alternatives. In this paper, we introduce a unifying framework to understand and derive these sequence models, inspired by the empirical importance of associative recall, the capability to retrieve contextually relevant tokens. We formalize associative recall as a two-step process, memorization and retrieval, casting memorization as a regression problem. Layers that combine these two steps perform associative recall via ``test-time regression'' over its input tokens. Prominent layers, including linear attention, state-space models, fast-weight programmers, online learners, and softmax attention, arise as special cases defined by three design choices: the regression weights, the regressor function class, and the test-time optimization algorithm. Our approach clarifies how linear attention fails to capture inter-token correlations and offers a mathematical justification for the empirical effectiveness of query-key normalization in softmax attention. Further, it illuminates unexplored regions within the design space, which we use to derive novel higher-order generalizations of softmax attention. Beyond unification, our work bridges sequence modeling with classic regression methods, a field with extensive literature, paving the way for developing more powerful and theoretically principled architectures.", "title": "Test-time regression: a unifying framework for designing sequence models with associative memory"}
{"id": "2501.13986", "reasoning_step": "Upon deep diving into the paper 'An Efficient Sparse Kernel Generator for O(3)-Equivariant Deep Networks,' I find the focus on optimizing the Clebsch-Gordon (CG) tensor product for rotation equivariant neural networks in computational chemistry intriguing. The authors address a critical bottleneck in these models by introducing a GPU sparse kernel generator, which is a novel approach to handling the computational intensity of CG tensor products. Their method leverages static analysis, JIT compilation, and kernel fusion to achieve significant speedups. However, I am cautious about the generalizability of their performance claims across diverse hardware and model configurations, as the benchmarks are heavily focused on specific NVIDIA and AMD GPUs. Additionally, while the speedups over e3nn are impressive, the comparison with NVIDIA's cuEquivariance shows mixed results, especially for backward passes and second derivatives, raising questions about the robustness of their optimizations. The fusion of CG tensor products with graph convolution is a promising idea, but I wonder about the scalability of this approach for very large graphs where memory constraints might be more severe. Lastly, their novel identity for higher partial derivatives is a clever workaround, but its practical impact on training stability and convergence needs further exploration. These insights will guide my critical summary and evaluation.", "problem_background": "The paper addresses the computational bottleneck in rotation equivariant neural networks, particularly in computational chemistry, where models like Nequip and MACE rely on the Clebsch-Gordon (CG) tensor product to maintain geometric consistency in predictions of molecular properties. The CG tensor product, a core operation that combines feature vectors while preserving rotation equivariance, is computationally expensive due to its low arithmetic intensity and irregular patterns, often requiring millions of evaluations on large datasets. This inefficiency hinders the scalability of equivariant models for tasks such as interatomic potential calculations and molecular dynamics simulations. The authors aim to solve this by developing an efficient sparse kernel generator for GPUs to accelerate the CG tensor product and its derivatives, thereby enhancing training and inference performance.", "slug": "efficient-sparse-kernel-generator-equivariant-networks", "one_sentence_summary": "This paper introduces a GPU sparse kernel generator for the Clebsch-Gordon tensor product in O(3)-equivariant deep networks, achieving significant speedups (up to 10x over e3nn and 1.3x-2.0x over cuEquivariance) by leveraging JIT compilation, static analysis, and kernel fusion, particularly enhancing performance in computational chemistry models like Nequip and MACE.", "preference": "unknown", "updated": "2025-05-12", "top_p": 0.8, "method": "The proposed method introduces a GPU sparse kernel generator for the Clebsch-Gordon (CG) tensor product in O(3)-equivariant deep networks. The core idea is to optimize the computation by exploiting sparsity and structure in the CG tensor through Just-in-Time (JIT) compilation, static analysis at compile-time, and kernel fusion. Key steps include: 1) Using JIT compilation to generate kernels that only compute nonzero entries of the sparse tensor, avoiding unnecessary operations; 2) Performing static analysis to schedule computations that minimize global memory traffic by breaking the tensor product into subkernels fitting into GPU registers; 3) Employing warp-level parallelism to ensure asynchronous execution without block-level synchronization; 4) Fusing the CG tensor product with graph convolution operations to reduce intermediate storage and memory writes; 5) Providing optimized kernels for gradients and a novel identity for higher partial derivatives using existing forward and backward pass kernels. This approach aims to maximize instruction-level parallelism and data reuse, significantly reducing computational overhead compared to dense linear algebra approaches.", "created": "2025-05-08", "authors": ["Vivek Bharadwaj", "Austin Glover", "Aydin Buluc", "James Demmel"], "score": 0.8870864242651173, "experiment": "The experiments were conducted on NVIDIA A100, A5000, and AMD MI250x GPUs, using benchmarks from chemical foundation models like Nequip and MACE, with datasets including molecular structures (e.g., DHFR, SARS-COV-2 spike, carbon lattice) and large atomic systems (e.g., 5184-atom water box). The setup compared the proposed kernels against e3nn (v0.5.6) and NVIDIA's cuEquivariance (v0.4.0), measuring throughput for forward, backward, and second derivative passes, as well as fused graph convolution performance. Results showed significant speedups over e3nn, with median FP32 forward pass improvements of 5.9x and up to 10x on complex configurations. Against cuEquivariance, speedups ranged from 1.3x to 2.0x for specific configurations (e.g., DiffDock), though backward pass performance was near parity or slightly lower (0.72x to 1.32x). Second derivative kernels showed mixed results, with speedups over e3nn (5.5x to 35x) but often slower than cuEquivariance (median 0.73x in FP32). Fused convolution offered up to 1.3x speedup over cuEquivariance in FP64 on certain graphs but lagged in backward passes. The experimental design was comprehensive for targeted models and hardware but lacked broader hardware diversity and detailed analysis of scalability for very large graphs. Results generally matched expectations for forward pass improvements but highlighted areas for optimization in backward and derivative computations.", "institution": ["University of California, Berkeley", "Lawrence Berkeley National Laboratory"], "source_file": "2501.13986.json", "keywords": ["Graph Data", "Efficiency", "GNN", "Multimodality", "AI for Science"], "temperature": 0.1, "model": "grok-3", "further_thoughts": "The approach of fusing the CG tensor product with graph convolution is a significant step forward, as it addresses memory overhead in equivariant graph neural networks, a common challenge in computational chemistry. However, I am curious about its applicability to other domains where equivariance is crucial, such as robotics or 3D vision, where data structures and transformation groups might differ (e.g., SE(3) instead of O(3)). Could the static analysis and JIT compilation strategies be adapted to handle dynamic graph structures or real-time constraints in these fields? Additionally, the mixed performance against cuEquivariance suggests potential for hybrid approaches—combining the strengths of both libraries might yield even better results, especially for backward passes. Another avenue for exploration is the integration of low-precision arithmetic, as hinted by the authors, which could further accelerate computations on modern GPUs with tensor cores, potentially impacting energy efficiency in large-scale simulations. Lastly, connecting this work to recent advancements in privacy-preserving machine learning, could the kernel optimizations be used to reduce computational overhead in federated learning setups for chemical data, where data sensitivity is a concern? Such cross-disciplinary applications could broaden the impact of this research.", "lang": "en", "categories": ["cs.LG", "cs.AI"], "summary_time": "2025-05-15T03:06:39.623740+00:00", "abstract": "Rotation equivariant graph neural networks, i.e. networks designed to guarantee certain geometric relations between their inputs and outputs, yield state of the art performance on spatial deep learning tasks. They exhibit high data efficiency during training and significantly reduced inference time for interatomic potential calculations compared to classical approaches. Key to these models is the Clebsch-Gordon (CG) tensor product, a kernel that contracts two dense feature vectors with a highly-structured sparse tensor to produce a dense output vector. The operation, which may be repeated millions of times for typical equivariant models, is a costly and inefficient bottleneck. We introduce a GPU sparse kernel generator for the CG tensor product that provides significant speedups over the best existing open and closed-source implementations. Our implementation achieves high performance by carefully managing the limited GPU shared memory through static analysis at model compile-time, minimizing reads and writes to global memory. We break the tensor product into a series of smaller kernels with operands that fit entirely into registers, enabling us to emit long arithmetic instruction streams that maximize instruction-level parallelism. By fusing the CG tensor product with a subsequent graph convolution, we reduce both intermediate storage and global memory traffic over naive approaches that duplicate input data. We also provide optimized kernels for the gradient of the CG tensor product and a novel identity for the higher partial derivatives required to predict interatomic forces. Our kernels offer up to 1.3x speedup over NVIDIA's closed-source cuEquivariance package, as well as 10x speedup over the widely-used e3nn package. In FP64 precision, we offer up to 6.2x inference-time speedup for the MACE chemistry foundation model over the original unoptimized version.", "title": "An Efficient Sparse Kernel Generator for O(3)-Equivariant Deep Networks"}
{"id": "2501.14082", "reasoning_step": "Upon deep diving into the paper 'Communicating Activations Between Language Model Agents,' I find the core idea of using intermediate activations for inter-LM communication intriguing, as it bypasses the computational overhead of natural language generation. The motivation stems from the high inference costs and information loss associated with natural language communication between LLMs. The proposed method of activation communication (AC) is novel in its simplicity, using functions like sum, mean, and replace to merge activations from two models at specific layers. However, I am skeptical about the generalizability of the results across diverse model architectures without a learned mapping matrix (W), as activation spaces may not align naturally. The experiments show promising results, with up to 27% improvement over natural language debate (NLD), but the datasets used (e.g., MMLU subsets, GSM8k) might not fully represent real-world complexity. The compute savings are analytically convincing, but practical implementation overheads are underexplored. Additionally, the lack of interpretability in activation communication raises concerns for debugging and trust in critical applications. I also note that the 'replace' function consistently outperforms others, which might indicate that simply overwriting activations preserves more meaningful information in the receiving model's space. This leads me to question whether the method's effectiveness is overly reliant on specific layer choices (k=j=26) and whether this is robust across different tasks or model pairs. Overall, while the paper presents a compelling alternative to NLD, further exploration of activation space alignment and interpretability is crucial for broader adoption.", "problem_background": "The research addresses the high inference costs and information loss inherent in natural language communication between large language models (LLMs) used as autonomous agents. As LLMs are increasingly deployed for complex reasoning and decision-making tasks, multi-agent communication has emerged as a method to enhance their capabilities through collaboration. However, natural language as a medium scales poorly with the number of agents and messages, and it abstracts away rich internal representations that could be more informative. This work aims to solve these issues by proposing a more efficient and information-rich communication protocol using intermediate activations instead of natural language, potentially unlocking better performance with lower computational overhead.", "slug": "activation-communication-llm-agents", "one_sentence_summary": "This paper introduces Activation Communication (AC), a novel method for inter-LLM communication using intermediate activations instead of natural language, achieving up to 27% performance improvement over traditional methods with significantly reduced compute across coordination games and reasoning benchmarks.", "preference": "unknown", "updated": "2025-05-09", "top_p": 0.8, "method": "The proposed method, termed Activation Communication (AC), involves direct communication between language models (LMs) via their intermediate activations. Specifically, for two models A and B, the process is as follows: (1) pause model B's computation at an intermediate layer j; (2) combine B's activation at layer j with model A's activation at layer k using a function f (options include sum, mean, or replace); (3) pass the combined output to B's next layer j+1 and continue the forward pass until decoding. The method requires no additional task-specific parameters or data, leveraging frozen pre-trained models. For cases where activation spaces differ significantly, a task-agnostic linear mapping matrix W is learned once per model pair to project activations into a compatible space, trained on general text data to minimize MSE loss. This approach aims to preserve richer internal representations compared to natural language tokens and reduce compute by avoiding multiple full forward passes.", "created": "2025-05-07", "authors": ["Vignav Ramesh", "Kenneth Li"], "score": 0.8771230029222021, "experiment": "The experiments are conducted in two setups: multi-player coordination games (Countries and Tip Sheets) and seven reasoning benchmarks (Biographies, GSM8k, and five MMLU subsets). Datasets are chosen to span diverse domains, with coordination games testing information transfer and reasoning benchmarks evaluating complex task performance. Models tested include various sizes from the LLaMA family (3B to 8B) and across families (Qwen, Gemma) to assess generalizability. Baselines include single-model performance and Natural Language Debate (NLD), with AC tested using different functions (sum, mean, replace) at fixed layers (k=j=26, determined empirically). Results show AC, particularly with the 'replace' function, achieves up to 27% improvement over NLD across datasets with less than 1/4 the compute, as quantified by FLOPs analysis. The setup is reasonable for controlled testing, but the subset sampling (e.g., 100 samples per dataset) and fixed layer choice may limit robustness claims. The learned mapping matrix W shows inconsistent gains, likely due to out-of-distribution training data, though in-distribution training on GSM8k significantly boosts performance (78% vs. 64%). While results match the expectation of compute efficiency and performance gains, the lack of testing on larger models (>70B) and real-world dynamic tasks suggests potential gaps in practical applicability.", "institution": ["Kempner Institute for AI, Harvard University"], "source_file": "2501.14082.json", "keywords": ["Large Language Model", "Multi-Agent", "Reasoning", "Efficiency", "Representation Learning"], "temperature": 0.1, "model": "grok-3", "further_thoughts": "The concept of activation communication opens up fascinating avenues for rethinking how LLMs collaborate, particularly in resource-constrained environments where compute efficiency is paramount. However, the reliance on aligned activation spaces or a learned mapping matrix W raises questions about scalability across highly divergent model architectures or training regimes—could this method be extended to black-box models via API access by approximating activations through output embeddings? Additionally, the interpretability trade-off is significant; while activations carry high-entropy information, their opacity could hinder trust in safety-critical applications like medical or legal reasoning, suggesting a need for hybrid approaches combining natural language for transparency with activations for efficiency. This work also connects to broader discussions in representation learning, such as the platonic representation hypothesis mentioned in the paper, which posits universal latent structures across models—could AC be a stepping stone to uncovering such universals by studying cross-model activation mappings? Finally, integrating AC with techniques like Retrieval-Augmented Generation (RAG) could be a powerful direction, where activations from a knowledge-retrieval model enhance a reasoning model's context without verbose text exchanges, potentially revolutionizing real-time multi-agent systems.", "lang": "en", "categories": ["cs.CL", "cs.AI", "cs.LG"], "summary_time": "2025-05-10T02:59:26.993079+00:00", "abstract": "Communication between multiple language model (LM) agents has been shown to scale up the reasoning ability of LMs. While natural language has been the dominant medium for inter-LM communication, it is not obvious this should be the standard: not only does natural language communication incur high inference costs that scale quickly with the number of both agents and messages, but also the decoding process abstracts away too much rich information that could be otherwise accessed from the internal activations. In this work, we propose a simple technique whereby LMs communicate via activations; concretely, we pause an LM $\\textit{B}$'s computation at an intermediate layer, combine its current activation with another LM $\\textit{A}$'s intermediate activation via some function $\\textit{f}$, then pass $\\textit{f}$'s output into the next layer of $\\textit{B}$ and continue the forward pass till decoding is complete. This approach scales up LMs on new tasks with zero additional parameters and data, and saves a substantial amount of compute over natural language communication. We test our method with various functional forms $\\textit{f}$ on two experimental setups--multi-player coordination games and reasoning benchmarks--and find that it achieves up to $27.0\\%$ improvement over natural language communication across datasets with $<$$1/4$ the compute, illustrating the superiority and robustness of activations as an alternative \"language\" for communication between LMs.", "title": "Communicating Activations Between Language Model Agents"}
{"id": "2501.14249", "reasoning_step": null, "problem_background": "现有的大型语言模型（LLM）基准测试，如MMLU，已经被模型性能饱和，模型在这些测试上准确率超过90%，这限制了对AI能力精确测量的能力。论文的出发点是解决这一问题，提出一个更具挑战性的多模态基准测试HUMANITY'S LAST EXAM（HLE），旨在覆盖广泛学科，测试LLM在封闭式学术问题上的极限性能。", "slug": "humanitys-last-exam", "one_sentence_summary": "本文引入HUMANITY'S LAST EXAM基准测试，通过专家创建的挑战性多模态问题，解决现有LLM基准饱和问题，评估模型在封闭式学术任务中的能力。", "preference": "like", "updated": "2025-04-22", "top_p": 0.7, "method": "论文的方法是通过全球专家协作创建数据集，核心思想是确保问题具有高难度、原创性和非可搜索性。具体步骤包括：1. 招募近1000名专家提交问题，每个问题包括问题文本、答案规范、详细解答、学科和贡献者信息；2. 使用前沿LLM（如GPT-4O、Gemini 1.5 Pro）进行难度检查，筛选出模型无法正确回答的问题；3. 采用多阶段人类审查过程，包括初级反馈审查和组织者/专家批准，确保问题质量；4. 问题格式多样，包括多选题和精确匹配题，支持自动评分，并强调多模态（文本和图像）。", "created": "2025-04-19", "authors": ["Long Phan", "Alice Gatti", "Ziwen Han", "Nathaniel Li", "Josephina Hu", "Hugh Zhang", "Chen Bo Calvin Zhang", "Mohamed Shaaban", "John Ling", "Sean Shi", "Michael Choi", "Anish Agrawal", "Arnav Chopra", "Adam Khoja", "Ryan Kim", "Richard Ren", "Jason Hausenloy", "Oliver Zhang", "Mantas Mazeika", "Dmitry Dodonov", "Tung Nguyen", "Jaeho Lee", "Daron Anderson", "Mikhail Doroshenko", "Alun Cennyth Stokes", "Mobeen Mahmood", "Oleksandr Pokutnyi", "Oleg Iskra", "Jessica P. Wang", "John-Clark Levin", "Mstyslav Kazakov", "Fiona Feng", "Steven Y. Feng", "Haoran Zhao", "Michael Yu", "Varun Gangal", "Chelsea Zou", "Zihan Wang", "Serguei Popov", "Robert Gerbicz", "Geoff Galgon", "Johannes Schmitt", "Will Yeadon", "Yongki Lee", "Scott Sauers", "Alvaro Sanchez", "Fabian Giska", "Marc Roth", "Søren Riis", "Saiteja Utpala", "Noah Burns", "Gashaw M. Goshu", "Mohinder Maheshbhai Naiya", "Chidozie Agu", "Zachary Giboney", "Antrell Cheatom", "Francesco Fournier-Facio", "Sarah-Jane Crowson", "Lennart Finke", "Zerui Cheng", "Jennifer Zampese", "Ryan G. Hoerr", "Mark Nandor", "Hyunwoo Park", "Tim Gehrunger", "Jiaqi Cai", "Ben McCarty", "Alexis C Garretson", "Edwin Taylor", "Damien Sileo", "Qiuyu Ren", "Usman Qazi", "Lianghui Li", "Jungbae Nam", "John B. Wydallis", "Pavel Arkhipov", "Jack Wei Lun Shi", "Aras Bacho", "Chris G. Willcocks", "Hangrui Cao", "Sumeet Motwani", "Emily de Oliveira Santos", "Johannes Veith", "Edward Vendrow", "Doru Cojoc", "Kengo Zenitani", "Joshua Robinson", "Longke Tang", "Yuqi Li", "Joshua Vendrow", "Natanael Wildner Fraga", "Vladyslav Kuchkin", "Andrey Pupasov Maksimov", "Pierre Marion", "Denis Efremov", "Jayson Lynch", "Kaiqu Liang", "Aleksandar Mikov", "Andrew Gritsevskiy", "Julien Guillod", "Gözdenur Demir", "Dakotah Martinez", "Ben Pageler", "Kevin Zhou", "Saeed Soori", "Ori Press", "Henry Tang", "Paolo Rissone", "Sean R. Green", "Lina Brüssel", "Moon Twayana", "Aymeric Dieuleveut", "Joseph Marvin Imperial", "Ameya Prabhu", "Jinzhou Yang", "Nick Crispino", "Arun Rao", "Dimitri Zvonkine", "Gabriel Loiseau", "Mikhail Kalinin", "Marco Lukas", "Ciprian Manolescu", "Nate Stambaugh", "Subrata Mishra", "Tad Hogg", "Carlo Bosio", "Brian P Coppola", "Julian Salazar", "Jaehyeok Jin", "Rafael Sayous", "Stefan Ivanov", "Philippe Schwaller", "Shaipranesh Senthilkuma", "Andres M Bran", "Andres Algaba", "Kelsey Van den Houte", "Lynn Van Der Sypt", "Brecht Verbeken", "David Noever", "Alexei Kopylov", "Benjamin Myklebust", "Bikun Li", "Lisa Schut", "Evgenii Zheltonozhskii", "Qiaochu Yuan", "Derek Lim", "Richard Stanley", "Tong Yang", "John Maar", "Julian Wykowski", "Martí Oller", "Anmol Sahu", "Cesare Giulio Ardito", "Yuzheng Hu", "Ariel Ghislain Kemogne Kamdoum", "Alvin Jin", "Tobias Garcia Vilchis", "Yuexuan Zu", "Martin Lackner", "James Koppel", "Gongbo Sun", "Daniil S. Antonenko", "Steffi Chern", "Bingchen Zhao", "Pierrot Arsene", "Joseph M Cavanagh", "Daofeng Li", "Jiawei Shen", "Donato Crisostomi", "Wenjin Zhang", "Ali Dehghan", "Sergey Ivanov", "David Perrella", "Nurdin Kaparov", "Allen Zang", "Ilia Sucholutsky", "Arina Kharlamova", "Daniil Orel", "Vladislav Poritski", "Shalev Ben-David", "Zachary Berger", "Parker Whitfill", "Michael Foster", "Daniel Munro", "Linh Ho", "Shankar Sivarajan", "Dan Bar Hava", "Aleksey Kuchkin", "David Holmes", "Alexandra Rodriguez-Romero", "Frank Sommerhage", "Anji Zhang", "Richard Moat", "Keith Schneider", "Zakayo Kazibwe", "Don Clarke", "Dae Hyun Kim", "Felipe Meneguitti Dias", "Sara Fish", "Veit Elser", "Tobias Kreiman", "Victor Efren Guadarrama Vilchis", "Immo Klose", "Ujjwala Anantheswaran", "Adam Zweiger", "Kaivalya Rawal", "Jeffery Li", "Jeremy Nguyen", "Nicolas Daans", "Haline Heidinger", "Maksim Radionov", "Václav Rozhoň", "Vincent Ginis", "Christian Stump", "Niv Cohen", "Rafał Poświata", "Josef Tkadlec", "Alan Goldfarb", "Chenguang Wang", "Piotr Padlewski", "Stanislaw Barzowski", "Kyle Montgomery", "Ryan Stendall", "Jamie Tucker-Foltz", "Jack Stade", "T. Ryan Rogers", "Tom Goertzen", "Declan Grabb", "Abhishek Shukla", "Alan Givré", "John Arnold Ambay", "Archan Sen", "Muhammad Fayez Aziz", "Mark H Inlow", "Hao He", "Ling Zhang", "Younesse Kaddar", "Ivar Ängquist", "Yanxu Chen", "Harrison K Wang", "Kalyan Ramakrishnan", "Elliott Thornley", "Antonio Terpin", "Hailey Schoelkopf", "Eric Zheng", "Avishy Carmi", "Ethan D. L. Brown", "Kelin Zhu", "Max Bartolo", "Richard Wheeler", "Martin Stehberger", "Peter Bradshaw", "JP Heimonen", "Kaustubh Sridhar", "Ido Akov", "Jennifer Sandlin", "Yury Makarychev", "Joanna Tam", "Hieu Hoang", "David M. Cunningham", "Vladimir Goryachev", "Demosthenes Patramanis", "Michael Krause", "Andrew Redenti", "David Aldous", "Jesyin Lai", "Shannon Coleman", "Jiangnan Xu", "Sangwon Lee", "Ilias Magoulas", "Sandy Zhao", "Ning Tang", "Michael K. Cohen", "Orr Paradise", "Jan Hendrik Kirchner", "Maksym Ovchynnikov", "Jason O. Matos", "Adithya Shenoy", "Michael Wang", "Yuzhou Nie", "Anna Sztyber-Betley", "Paolo Faraboschi", "Robin Riblet", "Jonathan Crozier", "Shiv Halasyamani", "Shreyas Verma", "Prashant Joshi", "Eli Meril", "Ziqiao Ma", "Jérémy Andréoletti", "Raghav Singhal", "Jacob Platnick", "Volodymyr Nevirkovets", "Luke Basler", "Alexander Ivanov", "Seri Khoury", "Nils Gustafsson", "Marco Piccardo", "Hamid Mostaghimi", "Qijia Chen", "Virendra Singh", "Tran Quoc Khánh", "Paul Rosu", "Hannah Szlyk", "Zachary Brown", "Himanshu Narayan", "Aline Menezes", "Jonathan Roberts", "William Alley", "Kunyang Sun", "Arkil Patel", "Max Lamparth", "Anka Reuel", "Linwei Xin", "Hanmeng Xu", "Jacob Loader", "Freddie Martin", "Zixuan Wang", "Andrea Achilleos", "Thomas Preu", "Tomek Korbak", "Ida Bosio", "Fereshteh Kazemi", "Ziye Chen", "Biró Bálint", "Eve J. Y. Lo", "Jiaqi Wang", "Maria Inês S. Nunes", "Jeremiah Milbauer", "M Saiful Bari", "Zihao Wang", "Behzad Ansarinejad", "Yewen Sun", "Stephane Durand", "Hossam Elgnainy", "Guillaume Douville", "Daniel Tordera", "George Balabanian", "Hew Wolff", "Lynna Kvistad", "Hsiaoyun Milliron", "Ahmad Sakor", "Murat Eron", "Andrew Favre D. O.", "Shailesh Shah", "Xiaoxiang Zhou", "Firuz Kamalov", "Sherwin Abdoli", "Tim Santens", "Shaul Barkan", "Allison Tee", "Robin Zhang", "Alessandro Tomasiello", "G. Bruno De Luca", "Shi-Zhuo Looi", "Vinh-Kha Le", "Noam Kolt", "Jiayi Pan", "Emma Rodman", "Jacob Drori", "Carl J Fossum", "Niklas Muennighoff", "Milind Jagota", "Ronak Pradeep", "Honglu Fan", "Jonathan Eicher", "Michael Chen", "Kushal Thaman", "William Merrill", "Moritz Firsching", "Carter Harris", "Stefan Ciobâcă", "Jason Gross", "Rohan Pandey", "Ilya Gusev", "Adam Jones", "Shashank Agnihotri", "Pavel Zhelnov", "Mohammadreza Mofayezi", "Alexander Piperski", "David K. Zhang", "Kostiantyn Dobarskyi", "Roman Leventov", "Ignat Soroko", "Joshua Duersch", "Vage Taamazyan", "Andrew Ho", "Wenjie Ma", "William Held", "Ruicheng Xian", "Armel Randy Zebaze", "Mohanad Mohamed", "Julian Noah Leser", "Michelle X Yuan", "Laila Yacar", "Johannes Lengler", "Katarzyna Olszewska", "Claudio Di Fratta", "Edson Oliveira", "Joseph W. Jackson", "Andy Zou", "Muthu Chidambaram", "Timothy Manik", "Hector Haffenden", "Dashiell Stander", "Ali Dasouqi", "Alexander Shen", "Bita Golshani", "David Stap", "Egor Kretov", "Mikalai Uzhou", "Alina Borisovna Zhidkovskaya", "Nick Winter", "Miguel Orbegozo Rodriguez", "Robert Lauff", "Dustin Wehr", "Colin Tang", "Zaki Hossain", "Shaun Phillips", "Fortuna Samuele", "Fredrik Ekström", "Angela Hammon", "Oam Patel", "Faraz Farhidi", "George Medley", "Forough Mohammadzadeh", "Madellene Peñaflor", "Haile Kassahun", "Alena Friedrich", "Rayner Hernandez Perez", "Daniel Pyda", "Taom Sakal", "Omkar Dhamane", "Ali Khajegili Mirabadi", "Eric Hallman", "Kenchi Okutsu", "Mike Battaglia", "Mohammad Maghsoudimehrabani", "Alon Amit", "Dave Hulbert", "Roberto Pereira", "Simon Weber", "Handoko", "Anton Peristyy", "Stephen Malina", "Mustafa Mehkary", "Rami Aly", "Frank Reidegeld", "Anna-Katharina Dick", "Cary Friday", "Mukhwinder Singh", "Hassan Shapourian", "Wanyoung Kim", "Mariana Costa", "Hubeyb Gurdogan", "Harsh Kumar", "Chiara Ceconello", "Chao Zhuang", "Haon Park", "Micah Carroll", "Andrew R. Tawfeek", "Stefan Steinerberger", "Daattavya Aggarwal", "Michael Kirchhof", "Linjie Dai", "Evan Kim", "Johan Ferret", "Jainam Shah", "Yuzhou Wang", "Minghao Yan", "Krzysztof Burdzy", "Lixin Zhang", "Antonio Franca", "Diana T. Pham", "Kang Yong Loh", "Joshua Robinson", "Abram Jackson", "Paolo Giordano", "Philipp Petersen", "Adrian Cosma", "Jesus Colino", "Colin White", "Jacob Votava", "Vladimir Vinnikov", "Ethan Delaney", "Petr Spelda", "Vit Stritecky", "Syed M. Shahid", "Jean-Christophe Mourrat", "Lavr Vetoshkin", "Koen Sponselee", "Renas Bacho", "Zheng-Xin Yong", "Florencia de la Rosa", "Nathan Cho", "Xiuyu Li", "Guillaume Malod", "Orion Weller", "Guglielmo Albani", "Leon Lang", "Julien Laurendeau", "Dmitry Kazakov", "Fatimah Adesanya", "Julien Portier", "Lawrence Hollom", "Victor Souza", "Yuchen Anna Zhou", "Julien Degorre", "Yiğit Yalın", "Gbenga Daniel Obikoya", "Rai", "Filippo Bigi", "M. C. Boscá", "Oleg Shumar", "Kaniuar Bacho", "Gabriel Recchia", "Mara Popescu", "Nikita Shulga", "Ngefor Mildred Tanwie", "Thomas C. H. Lux", "Ben Rank", "Colin Ni", "Matthew Brooks", "Alesia Yakimchyk", "Huanxu", "Liu", "Stefano Cavalleri", "Olle Häggström", "Emil Verkama", "Joshua Newbould", "Hans Gundlach", "Leonor Brito-Santana", "Brian Amaro", "Vivek Vajipey", "Rynaa Grover", "Ting Wang", "Yosi Kratish", "Wen-Ding Li", "Sivakanth Gopi", "Andrea Caciolai", "Christian Schroeder de Witt", "Pablo Hernández-Cámara", "Emanuele Rodolà", "Jules Robins", "Dominic Williamson", "Vincent Cheng", "Brad Raynor", "Hao Qi", "Ben Segev", "Jingxuan Fan", "Sarah Martinson", "Erik Y. Wang", "Kaylie Hausknecht", "Michael P. Brenner", "Mao Mao", "Christoph Demian", "Peyman Kassani", "Xinyu Zhang", "David Avagian", "Eshawn Jessica Scipio", "Alon Ragoler", "Justin Tan", "Blake Sims", "Rebeka Plecnik", "Aaron Kirtland", "Omer Faruk Bodur", "D. P. Shinde", "Yan Carlos Leyva Labrador", "Zahra Adoul", "Mohamed Zekry", "Ali Karakoc", "Tania C. B. Santos", "Samir Shamseldeen", "Loukmane Karim", "Anna Liakhovitskaia", "Nate Resman", "Nicholas Farina", "Juan Carlos Gonzalez", "Gabe Maayan", "Earth Anderson", "Rodrigo De Oliveira Pena", "Elizabeth Kelley", "Hodjat Mariji", "Rasoul Pouriamanesh", "Wentao Wu", "Ross Finocchio", "Ismail Alarab", "Joshua Cole", "Danyelle Ferreira", "Bryan Johnson", "Mohammad Safdari", "Liangti Dai", "Siriphan Arthornthurasuk", "Isaac C. McAlister", "Alejandro José Moyano", "Alexey Pronin", "Jing Fan", "Angel Ramirez-Trinidad", "Yana Malysheva", "Daphiny Pottmaier", "Omid Taheri", "Stanley Stepanic", "Samuel Perry", "Luke Askew", "Raúl Adrián Huerta Rodríguez", "Ali M. R. Minissi", "Ricardo Lorena", "Krishnamurthy Iyer", "Arshad Anil Fasiludeen", "Ronald Clark", "Josh Ducey", "Matheus Piza", "Maja Somrak", "Eric Vergo", "Juehang Qin", "Benjámin Borbás", "Eric Chu", "Jack Lindsey", "Antoine Jallon", "I. M. J. McInnis", "Evan Chen", "Avi Semler", "Luk Gloor", "Tej Shah", "Marc Carauleanu", "Pascal Lauer", "Tran Đuc Huy", "Hossein Shahrtash", "Emilien Duc", "Lukas Lewark", "Assaf Brown", "Samuel Albanie", "Brian Weber", "Warren S. Vaz", "Pierre Clavier", "Yiyang Fan", "Gabriel Poesia Reis e Silva", "Long", "Lian", "Marcus Abramovitch", "Xi Jiang", "Sandra Mendoza", "Murat Islam", "Juan Gonzalez", "Vasilios Mavroudis", "Justin Xu", "Pawan Kumar", "Laxman Prasad Goswami", "Daniel Bugas", "Nasser Heydari", "Ferenc Jeanplong", "Thorben Jansen", "Antonella Pinto", "Archimedes Apronti", "Abdallah Galal", "Ng Ze-An", "Ankit Singh", "Tong Jiang", "Joan of Arc Xavier", "Kanu Priya Agarwal", "Mohammed Berkani", "Gang Zhang", "Zhehang Du", "Benedito Alves de Oliveira Junior", "Dmitry Malishev", "Nicolas Remy", "Taylor D. Hartman", "Tim Tarver", "Stephen Mensah", "Gautier Abou Loume", "Wiktor Morak", "Farzad Habibi", "Sarah Hoback", "Will Cai", "Javier Gimenez", "Roselynn Grace Montecillo", "Jakub Łucki", "Russell Campbell", "Asankhaya Sharma", "Khalida Meer", "Shreen Gul", "Daniel Espinosa Gonzalez", "Xavier Alapont", "Alex Hoover", "Gunjan Chhablani", "Freddie Vargus", "Arunim Agarwal", "Yibo Jiang", "Deepakkumar Patil", "David Outevsky", "Kevin Joseph Scaria", "Rajat Maheshwari", "Abdelkader Dendane", "Priti Shukla", "Ashley Cartwright", "Sergei Bogdanov", "Niels Mündler", "Sören Möller", "Luca Arnaboldi", "Kunvar Thaman", "Muhammad Rehan Siddiqi", "Prajvi Saxena", "Himanshu Gupta", "Tony Fruhauff", "Glen Sherman", "Mátyás Vincze", "Siranut Usawasutsakorn", "Dylan Ler", "Anil Radhakrishnan", "Innocent Enyekwe", "Sk Md Salauddin", "Jiang Muzhen", "Aleksandr Maksapetyan", "Vivien Rossbach", "Chris Harjadi", "Mohsen Bahaloohoreh", "Claire Sparrow", "Jasdeep Sidhu", "Sam Ali", "Song Bian", "John Lai", "Eric Singer", "Justine Leon Uro", "Greg Bateman", "Mohamed Sayed", "Ahmed Menshawy", "Darling Duclosel", "Dario Bezzi", "Yashaswini Jain", "Ashley Aaron", "Murat Tiryakioglu", "Sheeshram Siddh", "Keith Krenek", "Imad Ali Shah", "Jun Jin", "Scott Creighton", "Denis Peskoff", "Zienab EL-Wasif", "Ragavendran P", "Michael Richmond", "Joseph McGowan", "Tejal Patwardhan", "Hao-Yu Sun", "Ting Sun", "Nikola Zubić", "Samuele Sala", "Stephen Ebert", "Jean Kaddour", "Manuel Schottdorf", "Dianzhuo Wang", "Gerol Petruzella", "Alex Meiburg", "Tilen Medved", "Ali ElSheikh", "S Ashwin Hebbar", "Lorenzo Vaquero", "Xianjun Yang", "Jason Poulos", "Vilém Zouhar", "Sergey Bogdanik", "Mingfang Zhang", "Jorge Sanz-Ros", "David Anugraha", "Yinwei Dai", "Anh N. Nhu", "Xue Wang", "Ali Anil Demircali", "Zhibai Jia", "Yuyin Zhou", "Juncheng Wu", "Mike He", "Nitin Chandok", "Aarush Sinha", "Gaoxiang Luo", "Long Le", "Mickaël Noyé", "Michał Perełkiewicz", "Ioannis Pantidis", "Tianbo Qi", "Soham Sachin Purohit", "Letitia Parcalabescu", "Thai-Hoa Nguyen", "Genta Indra Winata", "Edoardo M. Ponti", "Hanchen Li", "Kaustubh Dhole", "Jongee Park", "Dario Abbondanza", "Yuanli Wang", "Anupam Nayak", "Diogo M. Caetano", "Antonio A. W. L. Wong", "Maria del Rio-Chanona", "Dániel Kondor", "Pieter Francois", "Ed Chalstrey", "Jakob Zsambok", "Dan Hoyer", "Jenny Reddish", "Jakob Hauser", "Francisco-Javier Rodrigo-Ginés", "Suchandra Datta", "Maxwell Shepherd", "Thom Kamphuis", "Qizheng Zhang", "Hyunjun Kim", "Ruiji Sun", "Jianzhu Yao", "Franck Dernoncourt", "Satyapriya Krishna", "Sina Rismanchian", "Bonan Pu", "Francesco Pinto", "Yingheng Wang", "Kumar Shridhar", "Kalon J. Overholt", "Glib Briia", "Hieu Nguyen", "David", "Soler Bartomeu", "Tony CY Pang", "Adam Wecker", "Yifan Xiong", "Fanfei Li", "Lukas S. Huber", "Joshua Jaeger", "Romano De Maddalena", "Xing Han Lù", "Yuhui Zhang", "Claas Beger", "Patrick Tser Jern Kon", "Sean Li", "Vivek Sanker", "Ming Yin", "Yihao Liang", "Xinlu Zhang", "Ankit Agrawal", "Li S. Yifei", "Zechen Zhang", "Mu Cai", "Yasin Sonmez", "Costin Cozianu", "Changhao Li", "Alex Slen", "Shoubin Yu", "Hyun Kyu Park", "Gabriele Sarti", "Marcin Briański", "Alessandro Stolfo", "Truong An Nguyen", "Mike Zhang", "Yotam Perlitz", "Jose Hernandez-Orallo", "Runjia Li", "Amin Shabani", "Felix Juefei-Xu", "Shikhar Dhingra", "Orr Zohar", "My Chiffon Nguyen", "Alexander Pondaven", "Abdurrahim Yilmaz", "Xuandong Zhao", "Chuanyang Jin", "Muyan Jiang", "Stefan Todoran", "Xinyao Han", "Jules Kreuer", "Brian Rabern", "Anna Plassart", "Martino Maggetti", "Luther Yap", "Robert Geirhos", "Jonathon Kean", "Dingsu Wang", "Sina Mollaei", "Chenkai Sun", "Yifan Yin", "Shiqi Wang", "Rui Li", "Yaowen Chang", "Anjiang Wei", "Alice Bizeul", "Xiaohan Wang", "Alexandre Oliveira Arrais", "Kushin Mukherjee", "Jorge Chamorro-Padial", "Jiachen Liu", "Xingyu Qu", "Junyi Guan", "Adam Bouyamourn", "Shuyu Wu", "Martyna Plomecka", "Junda Chen", "Mengze Tang", "Jiaqi Deng", "Shreyas Subramanian", "Haocheng Xi", "Haoxuan Chen", "Weizhi Zhang", "Yinuo Ren", "Haoqin Tu", "Sejong Kim", "Yushun Chen", "Sara Vera Marjanović", "Junwoo Ha", "Grzegorz Luczyna", "Jeff J. Ma", "Zewen Shen", "Dawn Song", "Cedegao E. Zhang", "Zhun Wang", "Gaël Gendron", "Yunze Xiao", "Leo Smucker", "Erica Weng", "Kwok Hao Lee", "Zhe Ye", "Stefano Ermon", "Ignacio D. Lopez-Miguel", "Theo Knights", "Anthony Gitter", "Namkyu Park", "Boyi Wei", "Hongzheng Chen", "Kunal Pai", "Ahmed Elkhanany", "Han Lin", "Philipp D. Siedler", "Jichao Fang", "Ritwik Mishra", "Károly Zsolnai-Fehér", "Xilin Jiang", "Shadab Khan", "Jun Yuan", "Rishab Kumar Jain", "Xi Lin", "Mike Peterson", "Zhe Wang", "Aditya Malusare", "Maosen Tang", "Isha Gupta", "Ivan Fosin", "Timothy Kang", "Barbara Dworakowska", "Kazuki Matsumoto", "Guangyao Zheng", "Gerben Sewuster", "Jorge Pretel Villanueva", "Ivan Rannev", "Igor Chernyavsky", "Jiale Chen", "Deepayan Banik", "Ben Racz", "Wenchao Dong", "Jianxin Wang", "Laila Bashmal", "Duarte V. Gonçalves", "Wei Hu", "Kaushik Bar", "Ondrej Bohdal", "Atharv Singh Patlan", "Shehzaad Dhuliawala", "Caroline Geirhos", "Julien Wist", "Yuval Kansal", "Bingsen Chen", "Kutay Tire", "Atak Talay Yücel", "Brandon Christof", "Veerupaksh Singla", "Zijian Song", "Sanxing Chen", "Jiaxin Ge", "Kaustubh Ponkshe", "Isaac Park", "Tianneng Shi", "Martin Q. Ma", "Joshua Mak", "Sherwin Lai", "Antoine Moulin", "Zhuo Cheng", "Zhanda Zhu", "Ziyi Zhang", "Vaidehi Patil", "Ketan Jha", "Qiutong Men", "Jiaxuan Wu", "Tianchi Zhang", "Bruno Hebling Vieira", "Alham Fikri Aji", "Jae-Won Chung", "Mohammed Mahfoud", "Ha Thi Hoang", "Marc Sperzel", "Wei Hao", "Kristof Meding", "Sihan Xu", "Vassilis Kostakos", "Davide Manini", "Yueying Liu", "Christopher Toukmaji", "Jay Paek", "Eunmi Yu", "Arif Engin Demircali", "Zhiyi Sun", "Ivan Dewerpe", "Hongsen Qin", "Roman Pflugfelder", "James Bailey", "Johnathan Morris", "Ville Heilala", "Sybille Rosset", "Zishun Yu", "Peter E. Chen", "Woongyeong Yeo", "Eeshaan Jain", "Ryan Yang", "Sreekar Chigurupati", "Julia Chernyavsky", "Sai Prajwal Reddy", "Subhashini Venugopalan", "Hunar Batra", "Core Francisco Park", "Hieu Tran", "Guilherme Maximiano", "Genghan Zhang", "Yizhuo Liang", "Hu Shiyu", "Rongwu Xu", "Rui Pan", "Siddharth Suresh", "Ziqi Liu", "Samaksh Gulati", "Songyang Zhang", "Peter Turchin", "Christopher W. Bartlett", "Christopher R. Scotese", "Phuong M. Cao", "Aakaash Nattanmai", "Gordon McKellips", "Anish Cheraku", "Asim Suhail", "Ethan Luo", "Marvin Deng", "Jason Luo", "Ashley Zhang", "Kavin Jindel", "Jay Paek", "Kasper Halevy", "Allen Baranov", "Michael Liu", "Advaith Avadhanam", "David Zhang", "Vincent Cheng", "Brad Ma", "Evan Fu", "Liam Do", "Joshua Lass", "Hubert Yang", "Surya Sunkari", "Vishruth Bharath", "Violet Ai", "James Leung", "Rishit Agrawal", "Alan Zhou", "Kevin Chen", "Tejas Kalpathi", "Ziqi Xu", "Gavin Wang", "Tyler Xiao", "Erik Maung", "Sam Lee", "Ryan Yang", "Roy Yue", "Ben Zhao", "Julia Yoon", "Sunny Sun", "Aryan Singh", "Ethan Luo", "Clark Peng", "Tyler Osbey", "Taozhi Wang", "Daryl Echeazu", "Hubert Yang", "Timothy Wu", "Spandan Patel", "Vidhi Kulkarni", "Vijaykaarti Sundarapandiyan", "Ashley Zhang", "Andrew Le", "Zafir Nasim", "Srikar Yalam", "Ritesh Kasamsetty", "Soham Samal", "Hubert Yang", "David Sun", "Nihar Shah", "Abhijeet Saha", "Alex Zhang", "Leon Nguyen", "Laasya Nagumalli", "Kaixin Wang", "Alan Zhou", "Aidan Wu", "Jason Luo", "Anwith Telluri", "Summer Yue", "Alexandr Wang", "Dan Hendrycks"], "score": 0.58394, "experiment": "实验评估了多种前沿LLM（如GPT-4O、Grok-2、Claude 3.5 Sonnet等）在HLE上的性能，使用标准化提示（包括推理和最终答案格式），并采用O3-MINI作为判断器验证答案正确性。结果显示模型准确率低（例如GPT-4O为2.7%），校准错误高（RMS错误超过70%），表明方法改进明显，实验设置全面合理，覆盖不同类别（如数学、生物等），结果与预期一致，即突显当前LLM与人类专家水平的差距。", "institution": ["Center for AI Safety", "Scale AI"], "source_file": "2501.14249.json", "keywords": ["Large Language Model", "Multimodal Systems", "Benchmark", "Reasoning", "Human-AI Interaction", "AI Ethics"], "temperature": 0.5, "model": "grok-3-mini-latest", "further_thoughts": "HLE的工作强调了人类专家在AI基准创建中的关键作用，这可能启发未来基准设计更注重领域知识整合；此外，随着LLM能力的快速提升，HLE可与其他开放式任务基准结合，探索AI在实际应用中的泛化风险，并促进AI安全治理策略的制定。", "lang": "zh", "categories": ["cs.LG", "cs.AI", "cs.CL"], "summary_time": "2025-05-04T08:28:05.495015+00:00", "abstract": "Benchmarks are important tools for tracking the rapid advancements in large language model (LLM) capabilities. However, benchmarks are not keeping pace in difficulty: LLMs now achieve over 90\\% accuracy on popular benchmarks like MMLU, limiting informed measurement of state-of-the-art LLM capabilities. In response, we introduce Humanity's Last Exam (HLE), a multi-modal benchmark at the frontier of human knowledge, designed to be the final closed-ended academic benchmark of its kind with broad subject coverage. HLE consists of 2,500 questions across dozens of subjects, including mathematics, humanities, and the natural sciences. HLE is developed globally by subject-matter experts and consists of multiple-choice and short-answer questions suitable for automated grading. Each question has a known solution that is unambiguous and easily verifiable, but cannot be quickly answered via internet retrieval. State-of-the-art LLMs demonstrate low accuracy and calibration on HLE, highlighting a significant gap between current LLM capabilities and the expert human frontier on closed-ended academic questions. To inform research and policymaking upon a clear understanding of model capabilities, we publicly release HLE at https://lastexam.ai.", "title": "Humanity's Last Exam"}
{"id": "2501.15674", "reasoning_step": "在深入阅读《TensorLLM: Tensorising Multi-Head Attention for Enhanced Reasoning and Compression in LLMs》这篇论文时，我首先关注了其核心创新点：通过多头注意力（MHA）权重的高维张量化（Tensorisation）和Tucker分解来提升大型语言模型（LLMs）的推理能力并实现参数压缩。论文提出了一种直观的方法，利用MHA的领域知识，即同一层内的注意力头共享相似抽象层次但具有不同特化功能，从而通过共享因子矩阵的方式对MHA权重进行结构化去噪和压缩。这种方法试图解决现有技术（如LASER和TRAWL）在MHA块去噪效果不佳的问题。\n\n进一步分析方法部分，我注意到其核心在于将MHA权重张量化成3D或4D张量，并通过Tucker分解强制注意力头权重共享一个高维子空间。这种设计基于对注意力头功能的直觉，但缺乏对为何共享子空间能提升推理能力的理论支持或机制解释。此外，实验结果显示推理能力在多个数据集上有所提升，且压缩率高达247倍，但结果中损失值（Loss）在某些情况下反而增加（如HotPotQA数据集上的LLaMA2），这可能表明去噪过程对模型预测分布的影响并非完全正向。实验设计中，作者仅在单层上应用方法进行测试，缺乏对多层应用或层间交互影响的探讨，这可能限制了方法的实际应用价值。\n\n在批判性思考中，我发现论文的一个潜在问题是过度依赖直觉而非严谨的理论推导。例如，共享因子矩阵的设计是否真正捕捉到了注意力头的协同作用，仍需更多证据支持。此外，实验中未充分探讨超参数（如多线性秩）的选择对结果的影响，而作者在结论中也承认不同数据集需要不同超参数设置，这可能导致方法泛化性不足。另一个问题是，压缩率和推理能力提升之间是否存在权衡？高压缩率是否会导致模型在某些任务上的性能下降？这些问题未在论文中得到充分解答。\n\n总的来说，论文提出了一种新颖的MHA权重去噪和压缩方法，实验结果显示了一定的潜力，但其理论基础和实验设计的全面性仍有待加强。以下总结和分析将基于这些思考展开，确保客观评价论文的贡献和局限性。", "problem_background": "大型语言模型（LLMs）基于Transformer架构，在自然语言处理（NLP）中取得了巨大成功，但其过参数化特性导致推理和部署成本高昂。现有研究表明，通过结构化去噪和压缩模型权重，可以在不显著牺牲性能的情况下提升效率和推理能力。然而，当前方法（如LASER和TRAWL）主要聚焦于前馈网络（FFN）块的去噪，对Transformer核心组件——多头注意力（MHA）块的去噪效果不佳。论文试图解决这一问题，探索如何通过利用MHA的领域知识（即同一层内注意力头共享相似抽象层次但具有不同特化功能），提升LLMs的推理能力并实现MHA权重的高效压缩。", "slug": "tensorllm-mha-compression-reasoning", "one_sentence_summary": "本文提出了一种基于多头张量化和Tucker分解的框架，通过强制共享高维子空间对大型语言模型的多头注意力权重进行结构化去噪和压缩，显著提升推理能力并实现高达247倍的压缩率。", "preference": "unknown", "updated": "2025-05-16", "top_p": 0.8, "method": "论文提出了一种新颖的框架，通过多头张量化（Multi-Head Tensorisation）和Tucker分解对MHA权重进行结构化去噪和压缩。具体方法如下：\n- **核心思想**：基于MHA的领域知识，假设同一层内多个注意力头的权重共享一个高维子空间，通过强制共享因子矩阵的方式进行去噪和压缩，以提升推理能力。\n- **实现步骤**：\n  1. **多头张量化**：将MHA的查询（Q）、键（K）、值（V）和输出（O）权重矩阵从2D格式拆分为每个注意力头的子矩阵，并堆叠成3D张量（维度为$d_{model} \\times d_v \\times 4$），最终形成包含所有头权重的4D张量。\n  2. **共享因子矩阵的Tucker分解**：对每个注意力头的3D张量应用Tucker分解，但强制所有头共享一组相同的因子矩阵（$U^{(1)}, U^{(2)}, U^{(3)}$），仅核心张量（$G_i$）因头而异。这种设计确保各注意力头在同一高维子空间内编码不同信息。\n  3. **去噪与压缩**：通过最小化原始张量与分解后张量之间的Frobenius范数损失（$\\frac{1}{2} \\| \\mathcal{W}_{all} - \\mathcal{G}_{all} \\times_1 \\mathbf{U}^{(1)} \\times_2 \\mathbf{U}^{(2)} \\times_3 \\mathbf{U}^{(3)} \\|_F^2$），实现权重去噪，并通过设置较低的多线性秩（$R_n \\ll I_n$）实现参数压缩。\n- **关键点与批判**：方法创新在于利用MHA的直觉设计共享子空间，但缺乏理论依据证明为何共享因子矩阵能提升推理能力。此外，Tucker分解的多线性秩作为超参数，其选择对结果影响较大，但论文未提供系统性选择策略，可能导致方法在不同模型或数据集上的不稳定性。", "created": "2025-05-15", "authors": ["Yuxuan Gu", "Wuyang Zhou", "Giorgos Iacovides", "Danilo Mandic"], "score": 0.8682112693291416, "experiment": "实验在三个LLM模型（RoBERTa 125M、GPT-J 6B、LLaMA2 7B）上进行，涵盖编码器和解码器架构，并使用四个推理基准数据集（HotPotQA、FEVER、Bios Profession、BigBench-WikidataQA）评估性能。\n- **实验设置**：方法以层选择方式应用（每次仅对单层Transformer进行去噪和压缩），与现有方法（如LASER）进行公平比较。实验还包括与FFN去噪方法的联合测试，以及对MHA权重单独和联合张量化的消融研究。使用NVIDIA A100 GPU进行计算。\n- **结果分析**：\n  1. **推理能力提升**：在所有模型和数据集上，方法均提升了测试准确率（如GPT-J在BigBench-WikidataQA上从51.8%提升至68.81%），表明去噪对推理能力有正向影响。\n  2. **压缩效果**：MHA权重压缩率最高达247.3倍（GPT-J在HotPotQA上），显示出显著的参数效率提升。\n  3. **联合应用**：与LASER（FFN去噪）结合后，方法在大多数情况下进一步提升准确率（如LLaMA2在Bios Profession上从86.7%提升至87.07%）。\n  4. **消融研究**：联合张量化所有MHA权重（Q、K、V、O）优于单独处理，验证了方法设计的合理性。\n- **批判性评价**：尽管准确率提升明显，但某些情况下损失值（Loss）增加（如LLaMA2在HotPotQA上从3.15增至9.80），可能表明去噪过程对模型预测分布的负面影响未被充分考虑。实验仅限于单层应用，未探讨多层去噪的累积效应或层间交互影响。此外，超参数（如多线性秩）对不同数据集的影响未详细分析，限制了结果的泛化性解释。总体而言，实验设置较为合理，但不够全面，未能完全揭示方法在实际复杂场景中的潜力与局限。", "institution": ["Imperial College London"], "source_file": "2501.15674.json", "keywords": ["Large Language Model", "Transformer", "Reasoning", "Efficiency", "Multimodality"], "temperature": 0.1, "model": "grok-3", "further_thoughts": "论文提出的共享因子矩阵设计为MHA权重去噪提供了一种新颖视角，但其理论基础仍显薄弱。未来研究可以探索共享子空间的具体机制，例如通过可视化或分析因子矩阵的语义含义，验证其是否真正捕捉了注意力头的协同作用。此外，方法在高压缩率下的潜在性能权衡值得深入研究，尤其是在长上下文任务或多模态模型中，压缩可能对模型的泛化能力产生更大影响。另一个有趣的方向是将此方法与其他参数高效微调技术（如Low-Rank Adaptation）结合，探索去噪与微调的协同效应，尤其是在资源受限环境下的应用场景。最后，考虑到作者提到的超参数敏感性问题，可以引入自动化超参数搜索或元学习方法，以提升方法的通用性和实用性。", "lang": "zh", "categories": ["cs.CL", "cs.LG"], "summary_time": "2025-05-17T15:21:27.332557+00:00", "abstract": "The reasoning abilities of Large Language Models (LLMs) can be improved by structurally denoising their weights, yet existing techniques primarily focus on denoising the feed-forward network (FFN) of the transformer block, and can not efficiently utilise the Multi-head Attention (MHA) block, which is the core of transformer architectures. To address this issue, we propose a novel intuitive framework that, at its very core, performs MHA compression through a multi-head tensorisation process and the Tucker decomposition. This enables both higher-dimensional structured denoising and compression of the MHA weights, by enforcing a shared higher-dimensional subspace across the weights of the multiple attention heads. We demonstrate that this approach consistently enhances the reasoning capabilities of LLMs across multiple benchmark datasets, and for both encoder-only and decoder-only architectures, while achieving compression rates of up to $\\sim 250$ times in the MHA weights, all without requiring any additional data, training, or fine-tuning. Furthermore, we show that the proposed method can be seamlessly combined with existing FFN-only-based denoising techniques to achieve further improvements in LLM reasoning performance.", "title": "TensorLLM: Tensorising Multi-Head Attention for Enhanced Reasoning and Compression in LLMs"}
{"id": "2501.17176", "reasoning_step": null, "problem_background": "本研究的出发点是实现1:1的学生教师比例，以提供个性化教育和及时反馈，但由于资源限制（如教师短缺和预算问题），这一目标难以实现。特别是在计算机工程学入门编程课程中，学生数量众多，教师无法提供24/7的帮助，学生在独立作业时可能遇到困难。大型语言模型（LLMs）如ChatGPT的出现为虚拟教学助理提供了可能，但存在挑战：ChatGPT作为通用模型可能生成不准确信息、难以适应特定课程需求，且手动评估其性能成本高昂。本文解决了关键问题，包括评估ChatGPT在提供编程反馈方面的性能、提出成本效益高的自动评估方法（如通过结构化提示减少手动评估需求）、以及探讨LLMs在实际教育场景中的操作策略，以降低知识产权风险和提升教学效果。", "slug": "prompt-based-evaluation-chatgpt-teaching-assistant", "one_sentence_summary": "本文通过设计基于ICL和CoT的提示模板，实现了ChatGPT在编程教育中的成本效益评估和操作，显著降低了手动评估需求并提升了反馈的结构化分析。", "preference": "unknown", "updated": "2025-04-21", "top_p": 0.7, "method": "本研究的核心方法是设计一个基于提示的框架，使用In-Context Learning (ICL) 和Chain of Thought (CoT) 技术来构建提示模板。具体步骤包括：首先，在提示中指定函数名称、描述和一组单元测试；其次，提供示例输入-输出对，包括学生代码实现和结构化的反馈（使用Markdown格式分节，如\"Brief Code Explanation\"、\"Main Issues\"和\"Corrected Version\"）；第三，通过CoT方法在反馈中包含推理步骤和正确性判断；最后，实例化提示以分析学生代码，实现反馈的自动化提取和分析。核心思想是通过强制LLM生成结构化输出，便于程序化处理，而不修改模型本身，仅在推理阶段调整采样。", "created": "2025-04-18", "authors": ["Marc Ballestero-Ribó", "Daniel Ortiz-Martínez"], "score": 0.665011, "experiment": "实验评估了GPT-3.5T和GPT-4T在五个Python编程问题（Rotated Palindromes、Run Length Encoding、Number of Ones、In-place Partition、Sum of Pairs）上的性能，使用真实学生代码作为数据集（共500多个提交，包括运行时错误和断言测试）。实验设置包括：自动运行单元测试获取 ground truth，提取LLM反馈中的正确性预测、问题列表和修正版本，并计算指标如准确率、敏感性和特异性；用户研究涉及11名学生评估反馈的正确性和有用性。结果显示GPT-4T在代码正确性判断和问题识别上优于GPT-3.5T（准确率最高86.4%），但仍存在生成无关或错误反馈的问题；自动措施提供了错误反馈率的下界，节省了手动评估成本。实验设置合理全面，覆盖了多个研究问题，结果与预期一致，表明结构化提示显著提高了评估效率。", "institution": ["Universitat de Barcelona"], "source_file": "2501.17176.json", "keywords": ["Large Language Model", "Prompt Engineering", "In-Context Learning", "Human-AI Interaction", "AI Ethics"], "temperature": 0.5, "model": "grok-3-mini-latest", "further_thoughts": "本研究中提示工程的创新性值得关注，它不仅适用于编程教育，还可扩展到其他领域如医学或法律的AI辅助教学中，通过类似结构化输出减少人为错误；此外，与机器翻译中的质量估计技术结合，可能开发出更先进的反馈质量预测器，例如使用代码嵌入或句子嵌入训练模型来预估反馈准确性；未来，随着LLM模型的迭代（如Llama系列），可以探索细调模型以减少幻觉问题，或整合多模态输入提升交互性，但需注意伦理问题，如学生对AI反馈的过度信任可能影响批判性思维。", "lang": "zh", "categories": ["cs.CY", "cs.AI", "cs.CL"], "summary_time": "2025-05-04T08:26:25.137287+00:00", "abstract": "The dream of achieving a student-teacher ratio of 1:1 is closer than ever thanks to the emergence of large language models (LLMs). One potential application of these models in the educational field would be to provide feedback to students in university introductory programming courses, so that a student struggling to solve a basic implementation problem could seek help from an LLM available 24/7. This article focuses on studying three aspects related to such an application. First, the performance of two well-known models, GPT-3.5T and GPT-4T, in providing feedback to students is evaluated. The empirical results showed that GPT-4T performs much better than GPT-3.5T, however, it is not yet ready for use in a real-world scenario. This is due to the possibility of generating incorrect information that potential users may not always be able to detect. Second, the article proposes a carefully designed prompt using in-context learning techniques that allows automating important parts of the evaluation process, as well as providing a lower bound for the fraction of feedbacks containing incorrect information, saving time and effort. This was possible because the resulting feedback has a programmatically analyzable structure that incorporates diagnostic information about the LLM's performance in solving the requested task. Third, the article also suggests a possible strategy for implementing a practical learning tool based on LLMs, which is rooted on the proposed prompting techniques. This strategy opens up a whole range of interesting possibilities from a pedagogical perspective.", "title": "Prompt-Based Cost-Effective Evaluation and Operation of ChatGPT as a Computer Programming Teaching Assistant"}
{"id": "2501.18009", "reasoning_step": "在深入阅读这篇论文时，我首先关注了其核心问题：大型语言模型（LLMs）在开放性任务中的探索能力是否能与人类媲美，以及其探索策略的本质和局限性。论文以《Little Alchemy 2》游戏为实验范式，测试了LLMs在组合元素以发现新元素的能力，并通过回归分析和稀疏自编码器（SAE）分析了其探索策略（不确定性驱动和赋能驱动）。我注意到，论文指出大多数LLMs表现不如人类，主要是因为它们倾向于使用不确定性驱动的策略，而忽略了赋能（empowerment），这导致其在长期探索中表现不佳。特别有趣的是，SAE分析揭示了LLMs在处理不确定性和赋能信息时的层级差异——不确定性在早期层被处理，而赋能在中后期层才显现，这可能导致模型过早决策，限制了深度探索。此外，DeepSeek-R1和o1模型的表现突出，尤其是o1超过了人类水平，显示出更接近人类的探索策略平衡。我对论文中提到的‘快速思考’问题感到好奇，这是否真的是自回归架构的固有缺陷？还是可以通过训练或推理时计算资源的扩展来缓解？实验设计上，我质疑温度参数对探索策略的影响是否被充分解析，是否还有其他变量（如提示设计或上下文长度）未被考虑。此外，SAE分析虽然提供了有趣的洞察，但其因果干预实验的细节（附录中）似乎不够充分，是否真的能证明层级处理是探索失败的根本原因？这些问题促使我更深入地思考LLMs在开放性任务中的认知局限性，以及如何通过架构或训练范式改进其探索能力。", "problem_background": "大型语言模型（LLMs）在多种认知任务中展现出类人能力，但其探索能力——即在开放性任务中发现新信息或策略的能力——尚未被充分研究。探索是智能的重要组成部分，有助于长期适应性和性能提升，但现有研究多集中于狭窄的 bandit 任务，忽略了更广泛的开放性探索（如赋能驱动的探索）。本研究旨在解决三个关键问题：LLMs在开放性任务中的探索效果是否能媲美人类？它们采用何种探索策略？以及为何在探索任务中成功或失败？", "slug": "llms-exploration-fast-thinking", "one_sentence_summary": "本文通过《Little Alchemy 2》游戏评估大型语言模型（LLMs）的探索能力，发现大多数LLMs因过早决策和过度依赖不确定性驱动策略而表现不如人类，但o1和DeepSeek-R1通过平衡赋能和深入推理显著超越人类，揭示了推理深度和架构设计对开放性探索的重要性。", "preference": "unknown", "updated": "2025-05-13", "top_p": 0.8, "method": "本研究采用《Little Alchemy 2》游戏作为实验范式，玩家通过组合元素发现新元素，模拟开放性探索任务。研究方法包括以下核心步骤：\n* **任务设置**：测试了五种LLMs（GPT-4o, o1, LLaMA3.1-8B, LLaMA3.1-70B, DeepSeek-R1），通过API或计算集群运行，模型根据当前库存和历史试验记录选择元素组合，输出受限于有效游戏动作。\n* **探索策略分析**：通过回归模型分析不确定性驱动（基于元素使用频率）和赋能驱动（基于未来组合潜力，使用神经网络预测赋能值）策略对决策的影响，赋能值随试验结果动态更新。\n* **温度参数实验**：调整采样温度（0.0, 0.3, 0.7, 1.0）以研究随机性对探索与利用平衡的影响。\n* **推理过程分析**：对比GPT-4o和DeepSeek-R1的推理深度，分析推理痕迹的长度、类别多样性和令牌分配，揭示推理彻底性对探索性能的影响。\n* **稀疏自编码器（SAE）分析**：在模型各层提取元素嵌入，训练SAE以分解潜在表示，相关分析揭示不确定性和赋能值在Transformer层中的处理位置，并通过干预实验验证其因果关系。\n\n**批判性思考**：虽然方法设计较为全面，但温度参数的影响分析可能过于简单，未充分探讨其对赋能策略的具体作用机制。此外，SAE分析提供了潜在表示的洞察，但干预实验的细节不足，难以完全确认层级处理差异是否是探索失败的根本原因。赋能值的计算依赖神经网络预测，可能引入偏差，未讨论预测模型的准确性对结果的影响。", "created": "2025-05-12", "authors": ["Lan Pan", "Hanbo Xie", "Robert C. Wilson"], "score": 0.7114023117102881, "experiment": "实验在《Little Alchemy 2》游戏中进行，数据集包括29,493名人类玩家的4,691,033次试验作为基准，LLMs被限制在500次试验内评估发现新元素的数量。实验设置包括五种LLMs，采样温度设为0.0至1.0，每种设置重复五次，旨在测试随机性对探索策略的影响。结果显示：\n* **性能对比**：大多数LLMs表现不如人类（平均发现42个元素），如LLaMA3.1-8B仅发现9个，LLaMA3.1-70B发现25个，GPT-4o发现35个；但DeepSeek-R1（85个）和o1（177个）显著优于人类，尤其是o1表现出强大的探索能力。\n* **策略分析**：回归分析表明，除o1外，LLMs主要依赖不确定性驱动策略，赋能权重接近零，而人类和o1能平衡两者；温度升高仅增强不确定性策略，未显著提升赋能驱动探索。\n* **推理深度**：DeepSeek-R1展现出更长的推理序列和多样化的推理类别，分配更多令牌于结果预测和组合分析，而GPT-4o推理浅显，限制了探索效果。\n* **SAE结果**：在LLaMA3.1-70B中，不确定性和选择在早期层（第1-2层）高度相关，而赋能在中后期层（第72层）才显现，表明模型可能过早决策，忽略赋能信息；干预实验支持这一因果关系。\n\n**批判性思考**：实验设置较为合理，涵盖了多种模型和温度参数，但500次试验的限制可能低估了LLMs在长期探索中的潜力，尤其是后期赋能策略的重要性未被充分测试。温度对赋能策略无显著影响的结论可能因实验设计局限而不够全面，未探讨其他潜在变量（如上下文长度或提示设计）的影响。此外，o1的优异表现可能与其固定温度（1.0）和独特训练方式有关，但论文未提供足够细节以解释其成功机制，需谨慎对待结果的普适性。", "institution": ["Georgia Institute of Technology"], "source_file": "2501.18009.json", "keywords": ["Large Language Model", "Reasoning", "Reinforcement Learning", "Human-AI Interaction", "Multimodal Systems"], "temperature": 0.1, "model": "grok-3", "further_thoughts": "本文揭示了LLMs在开放性探索任务中的‘快速思考’问题，即由于自回归架构和层级处理差异，模型倾向于在早期层基于不确定性做出决策，而忽略了中后期层的赋能信息。这一发现引发了对模型架构设计的深思：是否可以通过调整Transformer层间的交互机制或引入延迟决策模块来增强探索能力？此外，o1和DeepSeek-R1的成功提示‘测试时计算扩展’（test-time compute scaling）可能是一个有前景的方向，类似于人类在复杂任务中通过更多思考时间提升表现，未来研究可探索如何在训练或推理阶段动态分配计算资源以优化探索策略。另一个有趣的联系是与强化学习中探索-利用权衡的研究结合，LLMs是否可以借鉴RL中的内在动机机制（如基于世界模型分歧的探索）来提升赋能驱动策略？同时，本研究未充分讨论的文化或语境因素可能影响模型对赋能的理解，例如元素组合的语义关联可能因训练数据的文化偏见而不同，这为跨文化AI探索能力研究提供了新方向。", "lang": "zh", "categories": ["cs.AI", "q-bio.NC"], "summary_time": "2025-05-18T03:17:14.986201+00:00", "abstract": "Large Language Models (LLMs) have emerged with many intellectual capacities. While numerous benchmarks assess their intelligence, limited attention has been given to their ability to explore--an essential capacity for discovering new information and adapting to novel environments in both natural and artificial systems. The extent to which LLMs can effectively explore, particularly in open-ended tasks, remains unclear. This study investigates whether LLMs can surpass humans in exploration during an open-ended task, using Little Alchemy 2 as a paradigm, where agents combine elements to discover new ones. Results show most LLMs underperform compared to humans, except for the o1 model, with traditional LLMs relying primarily on uncertainty-driven strategies, unlike humans who balance uncertainty and empowerment. Results indicate that traditional reasoning-focused LLMs, such as GPT-4o, exhibit a significantly faster and less detailed reasoning process, limiting their exploratory performance. In contrast, the DeepSeek reasoning model demonstrates prolonged, iterative thought processes marked by repetitive analysis of combinations and past trials, reflecting a more thorough and human-like exploration strategy. Representational analysis of the models with Sparse Autoencoders (SAE) revealed that uncertainty and choices are represented at earlier transformer blocks, while empowerment values are processed later, causing LLMs to think too fast and make premature decisions, hindering effective exploration. These findings shed light on the limitations of LLM exploration and suggest directions for improving their adaptability.", "title": "Large Language Models Think Too Fast To Explore Effectively"}
{"id": "2501.18630", "reasoning_step": "Upon deep diving into 'Deformable Beta Splatting' (DBS), several aspects stand out for critical analysis. The paper introduces a novel approach to radiance field rendering by replacing Gaussian kernels with deformable Beta Kernels, which promise better geometric fidelity and memory efficiency. The use of Spherical Beta for color encoding is intriguing as it aims to decouple diffuse and specular components, potentially addressing limitations of Spherical Harmonics (SH) in 3D Gaussian Splatting (3DGS). The kernel-agnostic MCMC optimization strategy is a significant theoretical contribution, as it claims to simplify densification across different kernel types. However, I must scrutinize the experimental results for cherry-picking or over-optimization on specific datasets. The reported 45% parameter reduction and 1.5x rendering speed improvement over 3DGS-MCMC need validation for generalizability. Additionally, the paper acknowledges limitations like popping artifacts and struggles with mirror-like reflections, which could undermine practical deployment. I also note the potential bias in Beta Kernel optimization towards low-frequency representations if not carefully managed. These points will guide my critical summary, ensuring I balance appreciation of innovation with a rigorous assessment of claims and limitations.", "problem_background": "The research addresses limitations in 3D Gaussian Splatting (3DGS), a method for real-time radiance field rendering that, while efficient, struggles with capturing fine geometric details and complex view-dependent colors due to the smoothing effect of Gaussian kernels and the parameter-heavy low-order Spherical Harmonics (SH) for color encoding. The key problem solved is enhancing both geometric fidelity and color representation in real-time rendering, overcoming the inherent constraints of fixed-function mappings in Gaussian kernels and SH, which fail to adapt to diverse scene complexities and lighting conditions, thus improving visual quality over 3DGS and competing with state-of-the-art Neural Radiance Fields (NeRF) methods.", "slug": "deformable-beta-splatting", "one_sentence_summary": "Deformable Beta Splatting (DBS) enhances real-time radiance field rendering by introducing deformable Beta Kernels for superior geometric fidelity, Spherical Beta for efficient color encoding, and kernel-agnostic MCMC optimization, achieving state-of-the-art visual quality with 45% fewer parameters and 1.5x faster rendering than 3DGS-MCMC.", "preference": "unknown", "updated": "2025-05-07", "top_p": 0.8, "method": "Deformable Beta Splatting (DBS) introduces three core innovations for radiance field rendering:\n1. **Beta Kernel for Geometry Representation**: Inspired by the Beta distribution, this kernel replaces Gaussian kernels with a bounded, deformable function parameterized by a shape control parameter $b$, allowing adaptive representation of flat surfaces, sharp edges, and smooth regions. It starts with a Gaussian-like shape ($b=0$) and evolves during optimization to capture diverse geometries with minimal memory overhead.\n2. **Spherical Beta (SB) for Color Encoding**: This method extends the Beta Kernel to view-dependent color modeling, decoupling diffuse and specular components inspired by the Phong Reflection Model. It uses fewer parameters (linear scaling with lobes) compared to SH (quadratic scaling), enabling sharp specular highlights and high-frequency lighting effects.\n3. **Kernel-Agnostic Markov Chain Monte Carlo (MCMC) Optimization**: Building on 3DGS-MCMC, DBS proves mathematically that adjusting regularized opacity alone preserves distribution during densification, regardless of kernel type or clone count, simplifying optimization by eliminating complex scale adjustments. A Beta-based noise function is also introduced to maintain consistency and encourage exploration during training.", "created": "2025-05-06", "authors": ["Rong Liu", "Dylan Sun", "Meida Chen", "Yue Wang", "Andrew Feng"], "score": 0.8714605901877177, "experiment": "The experiments evaluate DBS on multiple datasets including Mip-NeRF 360, Tanks and Temples, Deep Blending, and NeRF Synthetic, using metrics like PSNR, SSIM, and LPIPS. The setup compares DBS against state-of-the-art implicit (Zip-NeRF) and explicit (3DGS-MCMC) methods, with initialization using Colmap SfM point clouds or random primitives. Results show DBS outperforming competitors in visual quality across nearly all datasets, with PSNR gains (e.g., 28.75 vs. 28.29 on Mip-NeRF 360 for DBS-full vs. 3DGS-MCMC) and rendering 1.5x faster (123.09 FPS vs. 82.46 FPS for 3DGS-MCMC). It also uses only 45% of the parameters (356.04 MB vs. 733.19 MB). The experimental design is comprehensive, covering diverse scenes and including ablation studies on kernel type, Spherical Beta lobes, and opacity regularization. However, the results might be overly optimistic due to potential tuning for specific datasets, and limitations like popping artifacts are noted but not quantified. The efficiency claims match expectations, though generalizability to untested scenarios remains a concern.", "institution": ["University of Southern California", "Institute for Creative Technologies"], "source_file": "2501.18630.json", "keywords": ["Representation Learning", "Efficiency", "Multimodality", "Generative Modeling"], "temperature": 0.1, "model": "grok-3", "further_thoughts": "The introduction of deformable Beta Kernels in DBS opens up intriguing possibilities for broader applications beyond radiance field rendering, such as in generative modeling for 3D content creation where adaptive geometry representation could enhance realism in synthetic data generation. The kernel-agnostic MCMC approach also suggests potential cross-pollination with other optimization-heavy fields like reinforcement learning for real-time control tasks, where distribution-preserving strategies could stabilize training in dynamic environments. However, a critical concern is whether the Beta Kernel's adaptability might lead to overfitting on training data distributions, especially in less constrained real-world scenarios not covered by the tested datasets. Comparing this work to recent advancements in diffusion models for 3D generation, such as those leveraging latent representations, could reveal whether combining DBS's explicit kernel approach with implicit latent spaces might yield even more compact and flexible scene representations. This intersection could be a fruitful area for future research, potentially addressing the noted limitations in handling mirror-like reflections and anisotropic effects.", "lang": "en", "categories": ["cs.CV", "cs.GR"], "summary_time": "2025-05-08T03:07:17.700212+00:00", "abstract": "3D Gaussian Splatting (3DGS) has advanced radiance field reconstruction by enabling real-time rendering. However, its reliance on Gaussian kernels for geometry and low-order Spherical Harmonics (SH) for color encoding limits its ability to capture complex geometries and diverse colors. We introduce Deformable Beta Splatting (DBS), a deformable and compact approach that enhances both geometry and color representation. DBS replaces Gaussian kernels with deformable Beta Kernels, which offer bounded support and adaptive frequency control to capture fine geometric details with higher fidelity while achieving better memory efficiency. In addition, we extended the Beta Kernel to color encoding, which facilitates improved representation of diffuse and specular components, yielding superior results compared to SH-based methods. Furthermore, Unlike prior densification techniques that depend on Gaussian properties, we mathematically prove that adjusting regularized opacity alone ensures distribution-preserved Markov chain Monte Carlo (MCMC), independent of the splatting kernel type. Experimental results demonstrate that DBS achieves state-of-the-art visual quality while utilizing only 45% of the parameters and rendering 1.5x faster than 3DGS-MCMC, highlighting the superior performance of DBS for real-time radiance field rendering. Interactive demonstrations and source code are available on our project website: https://rongliu-leo.github.io/beta-splatting/.", "title": "Deformable Beta Splatting"}
